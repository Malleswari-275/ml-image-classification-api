# ğŸš€ Production-Ready ML Image Classification API  
### FastAPI â€¢ TensorFlow/Keras â€¢ Docker â€¢ CI/CD (GitHub Actions)

---

## ğŸ“Œ Project Overview

This project demonstrates how to convert a trained Keras image classification model into a production-ready RESTful API. The model is served using FastAPI, containerized using Docker, and integrated with a CI/CD pipeline using GitHub Actions.

The goal of this project is to bridge the gap between machine learning development and real-world production deployment using MLOps best practices.

This API performs real-time inference on uploaded images and returns predicted class labels along with class probabilities.

---

## ğŸ¯ Key Features

- âœ… RESTful API using FastAPI  
- âœ… Image classification using TensorFlow/Keras  
- âœ… Model loaded once at startup (optimized inference)  
- âœ… Image preprocessing inside API  
- âœ… Docker containerization (multi-stage build)  
- âœ… Docker Compose for simplified local setup  
- âœ… Automated CI/CD pipeline with GitHub Actions  
- âœ… Unit tests using pytest  
- âœ… Structured logging & proper error handling  
- âœ… Example prediction outputs included  

---

## ğŸ›  Technology Stack

- Python 3.11  
- FastAPI  
- TensorFlow / Keras  
- NumPy  
- Pillow  
- Pytest  
- Docker  
- Docker Compose  
- GitHub Actions  

---

## ğŸ“‚ Project Structure

```
ML_Prediction/
â”‚
â”œâ”€â”€ .github/workflows/        # CI/CD workflow
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ model.py             # Model loading & prediction logic
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ my_classifier_model.h5
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ predictions/             # Example prediction outputs
â”‚   â”œâ”€â”€ example_prediction_1.json
â”‚   â””â”€â”€ example_prediction_2.json
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions (Local Development)

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the API

```bash
uvicorn src.main:app --reload
```

Open in browser:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ³ Run with Docker (Recommended)

### Build & Run

```bash
docker compose up --build
```

Or (older versions):

```bash
docker-compose up --build
```

API will be available at:

```
http://localhost:8000
```

---

## ğŸ“¡ API Endpoints

### ğŸ” Health Check

**GET** `/health`

Example:

```bash
curl http://localhost:8000/health
```

Response:

```json
{
  "status": "ok",
  "message": "API is healthy and model is loaded."
}
```

### ğŸ§  Predict Image

**POST** `/predict`

Example:

```bash
curl -X POST \
  -F "file=@digit.png" \
  http://localhost:8000/predict
```

Example Response:

```json
{
  "class_label": "7",
  "probabilities": [0.01, 0.02, 0.03, 0.04, 0.05, 0.02, 0.01, 0.80, 0.01, 0.01]
}
```

---

## ğŸ§ª Running Tests

```bash
pytest tests/
```

Expected output:

```
4 passed
```

---

## ğŸ”„ CI/CD Pipeline

This project includes a GitHub Actions workflow that automatically:

- âœ… Checks out repository code
- âœ… Sets up Python environment
- âœ… Installs dependencies
- âœ… Runs unit tests
- âœ… Builds Docker image

The pipeline is triggered on:

- Push to `main`
- Pull requests to `main`

You can view workflow runs in the **Actions** tab of the repository.

---

## ğŸ” Environment Variables

See `.env.example`

| Variable | Description |
|----------|-------------|
| MODEL_PATH | Path to trained model inside container |
| LOG_LEVEL | Logging level (DEBUG, INFO, etc.) |

---

## ğŸ“¦ Prediction Examples

The `predictions/` directory contains sample JSON outputs from successful inference requests. These demonstrate expected API behavior.

---

## ğŸš€ Future Enhancements

- ğŸ” Add authentication (JWT-based)
- ğŸ“Š Add model performance monitoring
- ğŸ“ˆ Add Prometheus metrics endpoint
- â˜ï¸ Deploy to AWS / GCP
- ğŸ§© Add model versioning
- ğŸ³ Push Docker image to container registry
- âš¡ Add GPU support
- ğŸ§ª Run containerized tests inside CI/CD pipeline

---

## ğŸ† What This Project Demonstrates

This project demonstrates:

- âœ… End-to-end ML model deployment
- âœ… REST API development for inference
- âœ… Production containerization
- âœ… Automated CI/CD workflows
- âœ… Clean architecture & modular code
- âœ… MLOps best practices

---